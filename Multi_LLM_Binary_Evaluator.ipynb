{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JyothiSupriya/MARITIME-SAFETY-CLASSIFICATION-USING-LLMs/blob/main/Multi_LLM_Binary_Evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8WwWsralBXI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OLLAMA_HOST'] = '127.0.0.1:11434'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import re\n",
        "import pandas as pd\n",
        "from tqdm import tqdm  # For progress bar (install with pip install tqdm)\n",
        "\n",
        "def parse_yes_no(response_text):\n",
        "    \"\"\"\n",
        "    Attempts to locate a 'Yes' or 'No' in the response_text.\n",
        "    Returns 'Yes', 'No', or 'Could not parse' if neither is found.\n",
        "    \"\"\"\n",
        "    # Convert to lowercase for easy searching\n",
        "    text_lower = response_text.lower()\n",
        "\n",
        "    if \"yes\" in text_lower:\n",
        "        return \"Yes\"\n",
        "    elif \"no\" in text_lower:\n",
        "        return \"No\"\n",
        "    else:\n",
        "        return \"Could not parse\"\n",
        "\n",
        "def evaluate_row_pair(record, question):\n",
        "    \"\"\"\n",
        "    Evaluates a single record-question pair using Ollama/Llama\n",
        "    and ensures we only return 'Yes' or 'No'.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "You are a safety expert. Evaluate the following record and answer the question with only one word: \"Yes\" or \"No\".\n",
        "\n",
        "Record: {record}\n",
        "Question: {question}\n",
        "\n",
        "Reply with ONLY \"Yes\" or \"No\" (and no other text).\n",
        "    \"\"\".strip()\n",
        "\n",
        "    try:\n",
        "        process = subprocess.run(\n",
        "            [\"ollama\", \"run\", \"llama3.3\"],  # model_name ∈ {\n",
        "                                           #   \"GEMMA7B\", \"LLAMA3.2\", \"MISTRAL7B\",\n",
        "                                           #   \"DEEPSEEK14B\", \"PHI4\", \"QWEN32B\",\n",
        "                                           #   \"GEMMA27B\", \"DEEPSEEK32B\", \"LLAMA3.3\"\n",
        "                                           # }\n",
        "            input=prompt,\n",
        "            text=True,\n",
        "            capture_output=True,\n",
        "            encoding=\"utf-8\",\n",
        "            errors=\"replace\"\n",
        "        )\n",
        "\n",
        "        if process.returncode == 0:\n",
        "            # Extract raw text and parse\n",
        "            raw_response = process.stdout.strip()\n",
        "            parsed_response = parse_yes_no(raw_response)\n",
        "            return parsed_response\n",
        "        else:\n",
        "            return f\"Error: {process.stderr.strip()}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def process_excel_data(input_file):\n",
        "    \"\"\"\n",
        "    Processes Excel data with row-wise record-question pairs\n",
        "    \"\"\"\n",
        "    # Read data and preserve row relationships\n",
        "    df = pd.read_excel(input_file).dropna(subset=[\"Record\", \"Question\"])\n",
        "\n",
        "    results = []\n",
        "    total_rows = len(df)\n",
        "\n",
        "    print(f\"Processing {total_rows} row pairs...\")\n",
        "\n",
        "    # Use tqdm for progress bar\n",
        "    for idx, row in tqdm(df.iterrows(), total=total_rows):\n",
        "        result = {\n",
        "            \"Record\": row[\"Record\"],\n",
        "            \"Question\": row[\"Question\"],\n",
        "            \"Response\": evaluate_row_pair(row[\"Record\"], row[\"Question\"])\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Configuration\n",
        "    input_file = \"/content/Models_response.xlsx\"  # Input file with Record and Question columns\n",
        "    output_file = \"llama3.3_3.xlsx\"  # Output file\n",
        "\n",
        "    # Process data\n",
        "    results_df = process_excel_data(input_file)\n",
        "\n",
        "    # Save results\n",
        "    results_df.to_excel(output_file, index=False)\n",
        "    print(f\"\\nResults saved to {output_file}\")\n",
        "    print(\"Sample output:\")\n",
        "    print(results_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEq9JQn3lSzi",
        "outputId": "3a05bd17-a935-46ae-f3ed-c41c2f3e6ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 5000 row pairs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5000/5000 [1:48:28<00:00,  1.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results saved to llama3.3_3.xlsx\n",
            "Sample output:\n",
            "                                              Record  \\\n",
            "0  While carrying out fire drill, the fire hoses ...   \n",
            "1  While carrying out fire drill, the fire hoses ...   \n",
            "2  While carrying out fire drill, the fire hoses ...   \n",
            "3  While carrying out fire drill, the fire hoses ...   \n",
            "4  While carrying out fire drill, the fire hoses ...   \n",
            "\n",
            "                                            Question Response  \n",
            "0  Is this record related to faulty equipment con...      Yes  \n",
            "1  Is this record related to unsafe conditions on...       No  \n",
            "2  Is this record related to communication failur...       No  \n",
            "3  Is this record related to poor visibility crea...       No  \n",
            "4  Is this record related to usage of mobile/cell...       No  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s2rFKHznmLk3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}